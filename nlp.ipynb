{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRpPJqg7y9WCPkmGgvCgV5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaibhavPachpute21/Colab/blob/main/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "Cw5mdFwDqstG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVcAiZPcksuj",
        "outputId": "c95f1e29-d143-468a-f43c-c650cab8c43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello bithces vaibhav here.', \"hey sal i'm really missing you yar.\", 'learning on gr8 learning']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "data=\"hello bithces vaibhav here. hey sal i'm really missing you yar. learning on gr8 learning \"\n",
        "\n",
        "tokens=nltk.sent_tokenize(data)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=nltk.word_tokenize(data)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK-bkQzImxHm",
        "outputId": "0ee69e52-22ad-439f-ab1b-0a447efff807"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'bithces', 'vaibhav', 'here', '.', 'hey', 'sal', 'i', \"'m\", 'really', 'missing', 'you', 'yar', '.', 'learning', 'on', 'gr8', 'learning']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utM4LjosnoPj",
        "outputId": "cc502972-eed6-4799-f60d-879a31ecbdc1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzzDw-8RnsMM",
        "outputId": "34264351-4e05-4ba5-e876-11c53389bbe2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "b0MrI2gRqkF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "portstem=PorterStemmer()\n",
        "words=['Like',\"Liking\",\"Likes\",\"gardening\"]\n",
        "\n",
        "for i in words:\n",
        "  print(i, \" : \", portstem.stem(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qGCITcRpg4a",
        "outputId": "f835cd2f-94f9-4360-db88-1c541503d2b8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Like  :  like\n",
            "Liking  :  like\n",
            "Likes  :  like\n",
            "gardening  :  garden\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "CR9lB76_r8b3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10qjEnTQsD3n",
        "outputId": "023462cb-aaad-4347-c7d3-9a7fb4f9273c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmati=WordNetLemmatizer()\n",
        "print(\"socks:\",lemmati.lemmatize(\"socks\"))\n",
        "print(\"likes:\",lemmati.lemmatize(\"likes\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOYUP6KUsRB3",
        "outputId": "d1c0ad92-0117-4a84-e5c6-526919c1755b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "socks: sock\n",
            "likes: like\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Stopwords\n"
      ],
      "metadata": {
        "id": "yYe7leV-t073"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "data=\"\"\"Data Science is one of the most important field to work today. It needs data to give predictions by using the past scenarios\"\"\"\n",
        "\n",
        "stop_word=set(stopwords.words('english'))\n",
        "\n",
        "print(stopwords.words() [620:680])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6W_cktAt4JL",
        "outputId": "abf2491d-8008-4049-cced-a997712050d3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ثمنمئة', 'تسعمئة', 'مائة', 'ثلاثمائة', 'أربعمائة', 'خمسمائة', 'ستمائة', 'سبعمائة', 'ثمانمئة', 'تسعمائة', 'عشرون', 'ثلاثون', 'اربعون', 'خمسون', 'ستون', 'سبعون', 'ثمانون', 'تسعون', 'عشرين', 'ثلاثين', 'اربعين', 'خمسين', 'ستين', 'سبعين', 'ثمانين', 'تسعين', 'بضع', 'نيف', 'أجمع', 'جميع', 'عامة', 'عين', 'نفس', 'لا سيما', 'أصلا', 'أهلا', 'أيضا', 'بؤسا', 'بعدا', 'بغتة', 'تعسا', 'حقا', 'حمدا', 'خلافا', 'خاصة', 'دواليك', 'سحقا', 'سرا', 'سمعا', 'صبرا', 'صدقا', 'صراحة', 'طرا', 'عجبا', 'عيانا', 'غالبا', 'فرادى', 'فضلا', 'قاطبة', 'كثيرا']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "data=nltk.word_tokenize(data)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxKDGvPzvaK8",
        "outputId": "9a83e32b-adc8-497e-b288-4f2bb45569b4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data',\n",
              " 'Science',\n",
              " 'is',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'important',\n",
              " 'field',\n",
              " 'to',\n",
              " 'work',\n",
              " 'today',\n",
              " '.',\n",
              " 'It',\n",
              " 'needs',\n",
              " 'data',\n",
              " 'to',\n",
              " 'give',\n",
              " 'predictions',\n",
              " 'by',\n",
              " 'using',\n",
              " 'the',\n",
              " 'past',\n",
              " 'scenarios']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stops=set(stopwords.words('english'))\n",
        "for word in data:\n",
        "  if word in stops:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMsH4t_fwE4H",
        "outputId": "ffd3bf4b-c317-47f2-84a9-17f4a5b16431"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is\n",
            "of\n",
            "the\n",
            "most\n",
            "to\n",
            "to\n",
            "by\n",
            "the\n"
          ]
        }
      ]
    }
  ]
}